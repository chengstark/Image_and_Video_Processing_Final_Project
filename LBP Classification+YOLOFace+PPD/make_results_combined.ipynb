{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import itertools\n",
    "from keras.models import model_from_json\n",
    "import os\n",
    "from skimage.feature import local_binary_pattern, draw_multiblock_lbp, multiblock_lbp\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_density(img):\n",
    "    train_filenames =  ['Liu137.jpg', 'Liu97.jpg', 'Liu78.jpg', 'Liu14.jpg', 'Liu69.jpg', 'Liu164.jpg', 'Liu138.jpg', 'Liu167.jpg', 'Liu107.jpg', 'Liu19.jpg', 'Liu52.jpg', 'Liu48.jpg', 'Liu5.jpg', 'Liu87.jpg', 'Liu148.jpg', 'Liu60.jpg', 'Liu116.jpg', 'Liu65.jpg', 'Liu168.jpg', 'Liu71.jpg', 'Liu22.jpg', 'Liu145.jpg', 'Liu112.jpg', 'Liu108.jpg', 'Liu141.jpg', 'Liu55.jpg', 'Liu117.jpg', 'Liu125.jpg', 'Liu73.jpg', 'Liu57.jpg', 'Liu23.jpg', 'Liu99.jpg', 'Liu152.jpg', 'Liu31.png', 'Liu81.jpg', 'Liu144.png', 'Liu92.jpg', 'Liu140.jpg', 'Liu82.jpg', 'Liu58.jpg', 'Liu95.jpg', 'Liu34.jpg', 'Liu124.jpg', 'Liu80.jpg', 'Liu77.jpg', 'Liu130.jpg', 'Liu106.jpg', 'Liu170.jpg', 'Liu171.jpg', 'Liu40.jpg', 'Liu85.jpg', 'Liu66.jpg', 'Liu4.jpg', 'Liu132.jpg', 'Liu84.jpg', 'Liu115.jpg', 'Liu83.jpg', 'Liu32.png', 'Liu39.jpg', 'Liu43.jpg', 'Liu62.jpg', 'Liu28.jpg', 'Liu13.jpg', 'Liu46.jpg', 'Liu162.jpg', 'Liu122.jpg', 'Liu10.jpg', 'Liu126.jpg', 'Liu36.jpg', 'Liu26.jpg', 'Liu119.jpg', 'Liu18.jpg', 'Liu136.jpg', 'Liu79.jpg', 'Liu155.jpg', 'Liu101.jpg', 'Liu157.jpg', 'Liu29.jpg', 'Liu75.jpg', 'Liu161.jpg', 'Liu118.jpg', 'Liu111.jpg', 'Liu96.jpg', 'Liu64.jpg', 'Liu109.jpg', 'Liu143.jpg', 'Liu25.jpg', 'Liu165.jpg', 'Liu142.jpg', 'Liu12.jpg', 'Liu41.jpg', 'Liu89.jpg', 'Liu147.jpg', 'Liu128.jpg', 'Liu156.jpg', 'Liu102.jpg', 'Liu38.jpg', 'Liu146.jpg', 'Liu42.jpg', 'Liu158.jpg', 'Liu17.jpg', 'Liu133.jpg', 'Liu135.jpg', 'Liu9.jpg', 'Liu24.jpg', 'Liu59.jpg', 'Liu15.jpg', 'Liu16.jpg', 'Liu3.jpg', 'Liu93.jpg', 'Liu139.jpg', 'Liu33.jpg', 'Liu113.jpg', 'Liu134.jpg', 'Liu86.jpg', 'Liu30.jpg', 'Liu2.jpg', 'Liu120.jpg', 'Liu11.jpg', 'Liu21.jpg', 'Liu68.jpg', 'Liu166.jpg', 'Liu63.jpg', 'Liu44.jpg', 'Liu90.jpg', 'Liu76.jpg', 'Liu54.jpg', 'Liu169.jpg', 'Liu53.jpg', 'Liu70.jpg', 'Liu67.jpg', 'Liu27.jpg', 'Liu154.jpg', 'Liu94.png', 'Liu49.jpg', 'Liu151.jpg', 'Liu7.jpg', 'Liu98.jpg', 'Liu45.jpg', 'Liu150.jpg', 'Liu91.jpg']\n",
    "    dim = (img.shape[1], img.shape[0])\n",
    "    mask_density = np.zeros_like(img).astype(np.float32)\n",
    "    for f in train_filenames:\n",
    "        img = cv2.imread('F:/Invisible Man/Images/Studio_Filtered/' + f, 0)\n",
    "        mask = cv2.imread('F:/Invisible Man/Images/Studio_Masks/'+f, 0)\n",
    "        mask.astype(np.float32)\n",
    "        mask = mask / 255\n",
    "        resized_mask = cv2.resize(mask, dim, interpolation = cv2.INTER_AREA)\n",
    "        mask_density += resized_mask\n",
    "\n",
    "    kernel = np.ones((3,3),np.float32)\n",
    "    mask_density = cv2.filter2D(mask_density,-1,kernel)\n",
    "    mask_density /= np.max(mask_density)\n",
    "    return mask_density\n",
    "\n",
    "# plt.imshow(mask_density, cmap='gray', vmin=0, vmax=1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = ['Liu100.jpg', 'Liu72.jpg', 'Liu104.jpg', 'Liu103.jpg', 'Liu88.jpg', 'Liu20.jpg', 'Liu123.jpg', 'Liu153.jpg', 'Liu163.jpg', 'Liu50.jpg', 'Liu1.jpg', 'Liu47.jpg', 'Liu37.jpg', 'Liu105.jpg', 'Liu6.jpg', 'Liu121.jpg', 'Liu149.png', 'Liu35.jpg', 'Liu56.jpg', 'Liu51.jpg', 'Liu61.jpg', 'Liu127.jpg', 'Liu160.jpg', 'Liu114.jpg', 'Liu8.jpg', 'Liu131.jpg']\n",
    "step = 20\n",
    "size = 120\n",
    "radius = 2\n",
    "n_points = 8 * radius\n",
    "image_source_folder = 'F:/Invisible Man/Images/Studio_Filtered/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "keras_model_name = 'model_acc_deeper'\n",
    "json_file = open('{}.json'.format(keras_model_name), 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(\"{}.h5\".format(keras_model_name))\n",
    "print(\"Loaded model from disk\")\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras.metrics.FalsePositives()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes = pickle.load(open('bayes.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename_pbar = tqdm(test_filenames)\n",
    "# throw_away_count = 0\n",
    "\n",
    "# for f in filename_pbar:\n",
    "#     filename_pbar.set_description(\"Processing %s\" % f)\n",
    "#     color = cv2.imread(image_source_folder + f)\n",
    "#     img = cv2.imread(image_source_folder + f, 0)\n",
    "\n",
    "#     n_blocks_x = img.shape[1] // size\n",
    "#     n_blocks_y = img.shape[0] // size\n",
    "    \n",
    "#     base = color.copy().astype(np.float32)\n",
    "#     overlay = np.zeros(base.shape).astype(np.float32)\n",
    "\n",
    "#     for y in range(0, img.shape[0], step):\n",
    "#         for x in range(0, img.shape[1], step):\n",
    "#             window = img[y:y + size, x:x + size]\n",
    "\n",
    "#             lbp = local_binary_pattern(window, n_points, radius, 'uniform')\n",
    "#             lbp_counts, _ = np.histogram(lbp, bins=np.arange(radius ** 8 + 1), density=True)\n",
    "\n",
    "#             if window.shape[0] == size and window.shape[1] == size:\n",
    "#                 pred = model.predict(np.asarray([lbp_counts]))\n",
    "#                 if pred[0] >= 0.8:\n",
    "#                     overlay = cv2.rectangle(overlay, (x, y), (x + size, y + size), (0, 0, 255), thickness=-1)\n",
    "#                     overlay = cv2.rectangle(overlay, (x, y), (x + size, y + size), (0, 0, 0), thickness=3)\n",
    "                    \n",
    "#     result = cv2.addWeighted(base, 1.0, overlay, 0.5, 1)\n",
    "#     cv2.imwrite('test_results/' + f, result)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Liu100.jpg | calculating neigbour votes :   0%|          | 0/26 [00:54<?, ?it/s]                            \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'max_iou_cnt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-207a2deccbe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;31m#                             (max_iou_bbox[0]+max_iou_bbox[2], max_iou_bbox[1]+max_iou_bbox[3]), (0, 0, 255), thickness=3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[0mresult3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m     \u001b[0mresult3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmax_iou_cnt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_results/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_result.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'max_iou_cnt' is not defined"
     ]
    }
   ],
   "source": [
    "def get_threshold(preds, percentile=75):\n",
    "    cluster_preds = np.asarray(preds).reshape(-1,1)\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0).fit(cluster_preds)\n",
    "    labels = kmeans.labels_\n",
    "    centers = kmeans.cluster_centers_\n",
    "    cluster_0, cluster_1 = cluster_preds[labels == 0], cluster_preds[labels == 1]\n",
    "\n",
    "    if np.mean(cluster_0) >= np.mean(cluster_1): \n",
    "        return np.percentile(cluster_0.flatten(), 75), cluster_0[np.argmin(np.abs(cluster_0 - centers[1][0]))][0]\n",
    "    else: \n",
    "        return np.percentile(cluster_1.flatten(), 75), cluster_1[np.argmin(np.abs(cluster_1 - centers[0][0]))][0]\n",
    "\n",
    "def calc_iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "    \n",
    "threshs = []\n",
    "filename_pbar = tqdm(test_filenames, bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "throw_away_count = 0\n",
    "for f in filename_pbar:\n",
    "    X_test = []\n",
    "    vote_recorder = []\n",
    "    filename_pbar.set_description(\"Processing %s\" % f)\n",
    "    color = cv2.imread(image_source_folder + f)\n",
    "    img = cv2.imread(image_source_folder + f, 0)\n",
    "    mask_density = get_mask_density(img)\n",
    "    filename_pbar.set_description(\"Processing %s\" % f+' | mask density calculated ')\n",
    "\n",
    "    n_blocks_x = img.shape[1] // size\n",
    "    n_blocks_y = img.shape[0] // size\n",
    "    \n",
    "    base = color.copy().astype(np.float32)\n",
    "    overlay = np.zeros(base.shape).astype(np.float32)\n",
    "    \n",
    "    for y in range(0, img.shape[0], step):\n",
    "        row_vote_recorder = []\n",
    "        for x in range(0, img.shape[1], step):\n",
    "            window = img[y:y + size, x:x + size]\n",
    "\n",
    "            lbp = local_binary_pattern(window, n_points, radius, 'uniform')\n",
    "            lbp_counts, _ = np.histogram(lbp, bins=np.arange(radius ** 8 + 1), density=True)\n",
    "\n",
    "            if window.shape[0] == size and window.shape[1] == size:\n",
    "                X_test.append(lbp_counts)\n",
    "                row_vote_recorder.append(0)\n",
    "        if len(row_vote_recorder) > 0:\n",
    "            vote_recorder.append(row_vote_recorder)\n",
    "    \n",
    "    X_test = np.asarray(X_test)\n",
    "    filename_pbar.set_description(\"Processing %s\" % f+' | lbp complete')\n",
    "    # make predictions\n",
    "    preds = model.predict(X_test)\n",
    "    preds = preds.flatten().tolist()\n",
    "    # calculate threshold\n",
    "    percentile_thresh, cluster_boundary_thresh = get_threshold(preds, percentile=50)\n",
    "    thresh = percentile_thresh\n",
    "    threshs.append(thresh)\n",
    "    filename_pbar.set_description(\"Processing %s\" % f+' | threshold {}'.format(thresh))\n",
    "    \n",
    "    pure_prediction_overlay = np.zeros(img.shape).astype(np.uint8)\n",
    "    \n",
    "    vote_recorder = np.asanyarray(vote_recorder)\n",
    "#     confidence_recorder = np.zeros_like(vote_recorder).astype(np.float32)\n",
    "    confidence_recorder = np.zeros((len(range(0, img.shape[0], step)), len(range(0, img.shape[1], step))))\n",
    "    # classify each window\n",
    "    idx = 0\n",
    "    y_idx = 0\n",
    "    for y in range(0, img.shape[0], step):\n",
    "        x_idx = 0\n",
    "        for x in range(0, img.shape[1], step):\n",
    "            window = img[y:y + size, x:x + size]\n",
    "            if window.shape[0] == size and window.shape[1] == size:\n",
    "                pred = preds[idx]\n",
    "                if pred > thresh:\n",
    "                    vote_recorder[y_idx][x_idx] += 1\n",
    "                    density_weighted_confidence = pred*np.sqrt(mask_density[y][x])\n",
    "\n",
    "                    confidence_recorder[y_idx][x_idx] += density_weighted_confidence\n",
    "                    overlay = cv2.rectangle(overlay, (x, y), (x + size, y + size), (0, 0, 255), thickness=-1)\n",
    "                    overlay = cv2.rectangle(overlay, (x, y), (x + size, y + size), (0, 0, 0), thickness=3)\n",
    "                    pure_prediction_overlay = cv2.rectangle(pure_prediction_overlay, (x, y), (x + size, y + size), 255, thickness=-1)\n",
    "                \n",
    "                idx += 1\n",
    "                x_idx +=1\n",
    "\n",
    "        y_idx += 1\n",
    "    result = cv2.addWeighted(base, 1.0, overlay, 0.5, 1)\n",
    "    cv2.imwrite('test_results/' + f.split('.')[0]+'_pred.png', result)\n",
    "    \n",
    "    \n",
    "#     filename_pbar.set_description(\"Processing %s\" % f+' | calculating Bayes ')\n",
    "\n",
    "#     bayes_results = []\n",
    "#     bayes_overlay_bw = np.zeros(img.shape).astype(np.float32)\n",
    "#     for y in range(vote_recorder.shape[0]):\n",
    "#         bayes_row = []\n",
    "#         for x in range(vote_recorder.shape[1]):\n",
    "#             if x-1>= 0 and x+1< vote_recorder.shape[1] and y-1>=0 and y+1 < vote_recorder.shape[0]:\n",
    "# #                 feature = np.asarray([[x*step, y*step, vote_recorder[y-1][x], vote_recorder[y+1][x], vote_recorder[y][x-1], vote_recorder[y][x+1]]]).astype(np.float64)\n",
    "#                 feature = np.asarray([[x*step, y*step]]).astype(np.float64)\n",
    "#                 bayes_pred = bayes.predict(feature)[0]\n",
    "#                 bayes_row.append(bayes_pred)\n",
    "    \n",
    "#         if len(bayes_row) > 0:\n",
    "#             bayes_results.append(bayes_row)\n",
    "\n",
    "#     bayes_results = np.asarray(bayes_results)\n",
    "#     filename_pbar.set_description(\"Processing %s\" % f+' | normalizing Bayes ')\n",
    "#     bayes_results = MinMaxScaler().fit_transform(bayes_results)\n",
    "\n",
    "#     filename_pbar.set_description(\"Processing %s\" % f+' | painting Bayes ')\n",
    "\n",
    "#     bayes_overlay_bw = np.zeros(img.shape).astype(np.float32)\n",
    "#     for y in range(vote_recorder.shape[0]):\n",
    "#         for x in range(vote_recorder.shape[1]):\n",
    "#             if x-1>= 0 and x+1< vote_recorder.shape[1] and y-1>=0 and y+1 < vote_recorder.shape[0]:\n",
    "#                 coord_x = x*step\n",
    "#                 coord_y = y*step\n",
    "#                 c = int(bayes_results[y-1][x-1]*255)\n",
    "#                 bayes_overlay_bw = cv2.rectangle(bayes_overlay_bw, (coord_x, coord_y), (coord_x + size, coord_y + size), c, thickness=-1)\n",
    "#     cv2.imwrite('test_results/' + f.split('.')[0]+'_bayes_heat.png', bayes_overlay_bw)\n",
    "\n",
    "    filename_pbar.set_description(\"Processing %s\" % f+' | calculating neigbour votes ')\n",
    "\n",
    "    n_neighbours = 3 # smaller values\n",
    "    neighbour_vote_recorder = []\n",
    "    for y in range(n_neighbours, vote_recorder.shape[0]-n_neighbours):\n",
    "        row_neighbour_vote = []\n",
    "        for x in range(n_neighbours, vote_recorder.shape[1]-n_neighbours):\n",
    "            row_neighbour_vote.append(np.sum(vote_recorder[y-n_neighbours:y+n_neighbours+1, x-n_neighbours:x+n_neighbours+1]))\n",
    "        neighbour_vote_recorder.append(row_neighbour_vote)\n",
    "    neighbour_vote_recorder = np.asanyarray(neighbour_vote_recorder)\n",
    "    \n",
    "    confidence_recorder = confidence_recorder / np.max(confidence_recorder)\n",
    "    unique_confidence = np.unique(confidence_recorder, return_counts=True)[0]\n",
    "    cmap_norm = matplotlib.colors.Normalize(vmin=np.min(unique_confidence), vmax=np.max(unique_confidence))\n",
    "    confidence_base = color.copy().astype(np.float32)\n",
    "    confidence_overlay = np.zeros_like(color)\n",
    "    confidence_overlay_adder = np.zeros_like(img).astype(np.float32)\n",
    "    confidence_overlay_bw = np.zeros_like(img)\n",
    "    for y in range(confidence_recorder.shape[0]):\n",
    "        for x in range(confidence_recorder.shape[1]):\n",
    "            neighbour_x = x - n_neighbours\n",
    "            confidence = confidence_recorder[y][x]\n",
    "            coord_y = y*step\n",
    "            coord_x = x*step\n",
    "\n",
    "            cmap = matplotlib.cm.get_cmap('rainbow')\n",
    "            rgba = cmap(confidence)\n",
    "            c = (int(rgba[2]*255), int(rgba[1]*255), int(rgba[0]*255))\n",
    "            c_bw = int(confidence > 0)*255\n",
    "            confidence_overlay_adder[coord_y:coord_y+size, coord_x:coord_x+size] += confidence\n",
    "            \n",
    "            confidence_overlay = cv2.rectangle(confidence_overlay, (coord_x, coord_y), (coord_x + size, coord_y + size), c, thickness=-1)\n",
    "            confidence_overlay_bw = cv2.rectangle(confidence_overlay_bw, (coord_x, coord_y), (coord_x + size, coord_y + size), c_bw, thickness=-1)\n",
    "\n",
    "#     cv2.imwrite('test_results/' + f.split('.')[0]+'_ori.png', color)\n",
    "    \n",
    "    unique_votes = np.unique(neighbour_vote_recorder, return_counts=True)[0]\n",
    "    vote_overlay_bw = np.zeros(img.shape).astype(np.float32)\n",
    "    for y in range(vote_recorder.shape[0]):\n",
    "        if y - n_neighbours < 0 or y + n_neighbours > vote_recorder.shape[0] - 1: continue\n",
    "        for x in range(vote_recorder.shape[1]):\n",
    "            if x - n_neighbours < 0 or x + n_neighbours > vote_recorder.shape[1] - 1: continue\n",
    "            neighbour_y = y - n_neighbours\n",
    "            neighbour_x = x - n_neighbours\n",
    "            vote = neighbour_vote_recorder[neighbour_y][neighbour_x]\n",
    "\n",
    "            coord_y = y*step\n",
    "            coord_x = x*step\n",
    "\n",
    "            c = int(255*(vote/np.max(unique_votes)))\n",
    "\n",
    "            vote_overlay_bw = cv2.rectangle(vote_overlay_bw, (coord_x, coord_y), (coord_x + size, coord_y + size), c, thickness=-1)\n",
    "    cv2.imwrite('test_results/' + f.split('.')[0]+'_bw_heat.png', vote_overlay_bw)\n",
    "\n",
    "    threshed_overlay = vote_overlay_bw.copy()\n",
    "    threshed_overlay[threshed_overlay >= (np.percentile(unique_votes, 70) / np.max(unique_votes))*255] = 255\n",
    "    threshed_overlay[threshed_overlay < (np.percentile(unique_votes, 70) / np.max(unique_votes))*255] = 0\n",
    "    threshed_overlay = np.uint8(threshed_overlay)\n",
    "    _, cnts, _ = cv2.findContours(threshed_overlay,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    _, prediction_cnts, _ = cv2.findContours(pure_prediction_overlay,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    _, confidence_cnts, _ = cv2.findContours(confidence_overlay_bw,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    confidence_cnts_areas = []\n",
    "    for idx, confidence_cnt in enumerate(confidence_cnts):\n",
    "        area = cv2.contourArea(confidence_cnt)\n",
    "        confidence_cnts_areas.append(area)\n",
    "    area_thresh = np.percentile(np.asarray(confidence_cnts_areas), 85)\n",
    "    max_confidence_bbox = None\n",
    "    max_confidence_cnt = None\n",
    "    max_normalized_confidence = -999\n",
    "    for idx, confidence_cnt in enumerate(confidence_cnts):\n",
    "        area = cv2.contourArea(confidence_cnt)\n",
    "        if area < area_thresh: continue\n",
    "        tmp_mask = np.zeros(img.shape).astype(np.float32)\n",
    "        confidence_cnt_mask = cv2.drawContours(tmp_mask, [confidence_cnt], 0, 255, -1)\n",
    "        confidence_sum = np.sum(confidence_overlay_adder[confidence_cnt_mask == 255])\n",
    "        normalized_confidence = confidence_sum / area\n",
    "#         print(np.sum(confidence_overlay_adder), confidence_sum, normalized_confidence, area)\n",
    "        if normalized_confidence > max_normalized_confidence:\n",
    "            mapax_normalized_confidence = normalized_confidence\n",
    "            max_confidence_bbox = cv2.boundingRect(confidence_cnt)\n",
    "            max_confidence_cnt = confidence_cnt\n",
    "    \n",
    "    confidence_overlay_wcnt = confidence_overlay.copy()\n",
    "    confidence_overlay_wcnt = cv2.drawContours(confidence_overlay_wcnt, [max_confidence_cnt], 0, (255, 255, 255), 3)\n",
    "    cv2.imwrite('test_results/' + f.split('.')[0]+'_confidence_heat.png', confidence_overlay_wcnt)\n",
    "    result4 = color.copy()\n",
    "    result4 = cv2.rectangle(result4, (max_confidence_bbox[0], max_confidence_bbox[1]), \n",
    "                            (max_confidence_bbox[0]+max_confidence_bbox[2], max_confidence_bbox[1]+max_confidence_bbox[3]), (0, 0, 255), thickness=3)\n",
    "    cv2.imwrite('test_results/' + f.split('.')[0]+'_result4.png', result4)\n",
    "    target_cnt = max(cnts, key = cv2.contourArea)\n",
    "    bounding_rec = cv2.boundingRect(target_cnt)\n",
    "    x,y,w,h = bounding_rec\n",
    "    \n",
    "#     max_iou_bbox = None\n",
    "#     max_iou_cnt = None\n",
    "#     max_iou = -999\n",
    "#     for idx, prediction_cnt in enumerate(prediction_cnts):\n",
    "#         x2,y2,w2,h2 = cv2.boundingRect(prediction_cnt)\n",
    "#         iou = calc_iou([x, y, x+w, y+h], [x2, y2, x2+w2, y2+h2])\n",
    "#         if iou > max_iou: \n",
    "#             max_iou = iou\n",
    "#             max_iou_bbox = [x2,y2,w2,h2]\n",
    "#             max_iou_cnt = prediction_cnt\n",
    "    \n",
    "    \n",
    "    target_overlay_mask = np.zeros(img.shape).astype(np.float32)\n",
    "    target_overlay_mask = cv2.drawContours(target_overlay_mask, [target_cnt], 0, 255, -1)\n",
    "    result = color.copy()\n",
    "    result = cv2.rectangle(result, (x, y), (x + w, y + h), (0, 0, 255), thickness=3)\n",
    "#     result2 = color.copy()\n",
    "#     result2 = cv2.rectangle(result2, (max_iou_bbox[0], max_iou_bbox[1]), \n",
    "#                             (max_iou_bbox[0]+max_iou_bbox[2], max_iou_bbox[1]+max_iou_bbox[3]), (0, 0, 255), thickness=3)\n",
    "    result3 = color.copy()\n",
    "    result3 = cv2.drawContours(result3, [max_iou_cnt], 0, (0, 0, 255), 3)\n",
    "\n",
    "    cv2.imwrite('test_results/' + f.split('.')[0]+'_result.png', result)\n",
    "\n",
    "    overlay_masks = []\n",
    "    all_cnts = np.zeros(img.shape).astype(np.float32)\n",
    "    for idx, cnt in enumerate(cnts):\n",
    "        overlay_mask = np.zeros(img.shape).astype(np.float32)\n",
    "        overlay_mask = cv2.drawContours(overlay_mask, cnts, idx, 255, -1)\n",
    "        all_cnts = cv2.drawContours(all_cnts, cnts, idx, 255, 2)\n",
    "#         cv2.imwrite('test_results/' + f.split('.')[0]+'_{}.png'.format(idx), overlay_mask)\n",
    "        overlay_masks.append(overlay_mask)\n",
    "    \n",
    "    cv2.imwrite('test_results/' + f.split('.')[0]+'_cnts.png', all_cnts)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(threshs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack masks together and make a probabilty histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
